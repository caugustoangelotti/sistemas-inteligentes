{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89062a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4bbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('emprego.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966b029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>58.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>79.33</td>\n",
       "      <td>Central</td>\n",
       "      <td>78.33</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>77.48</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>86.5</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>66.28</td>\n",
       "      <td>Placed</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Arts</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>57.80</td>\n",
       "      <td>Placed</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>56.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>Science</td>\n",
       "      <td>52.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>59.43</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>85.80</td>\n",
       "      <td>Central</td>\n",
       "      <td>73.60</td>\n",
       "      <td>Central</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.30</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>96.8</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>55.50</td>\n",
       "      <td>Placed</td>\n",
       "      <td>425000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>M</td>\n",
       "      <td>80.60</td>\n",
       "      <td>Others</td>\n",
       "      <td>82.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>77.60</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>74.49</td>\n",
       "      <td>Placed</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>M</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>60.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>72.00</td>\n",
       "      <td>Sci&amp;Tech</td>\n",
       "      <td>No</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>53.62</td>\n",
       "      <td>Placed</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>M</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>67.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>73.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>Yes</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Mkt&amp;Fin</td>\n",
       "      <td>69.72</td>\n",
       "      <td>Placed</td>\n",
       "      <td>295000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>F</td>\n",
       "      <td>74.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>66.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>60.23</td>\n",
       "      <td>Placed</td>\n",
       "      <td>204000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>M</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Central</td>\n",
       "      <td>58.00</td>\n",
       "      <td>Others</td>\n",
       "      <td>Science</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Comm&amp;Mgmt</td>\n",
       "      <td>No</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Mkt&amp;HR</td>\n",
       "      <td>60.22</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
       "0        1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
       "1        2      M  79.33  Central  78.33   Others   Science     77.48   \n",
       "2        3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
       "3        4      M  56.00  Central  52.00  Central   Science     52.00   \n",
       "4        5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
       "..     ...    ...    ...      ...    ...      ...       ...       ...   \n",
       "210    211      M  80.60   Others  82.00   Others  Commerce     77.60   \n",
       "211    212      M  58.00   Others  60.00   Others   Science     72.00   \n",
       "212    213      M  67.00   Others  67.00   Others  Commerce     73.00   \n",
       "213    214      F  74.00   Others  66.00   Others  Commerce     58.00   \n",
       "214    215      M  62.00  Central  58.00   Others   Science     53.00   \n",
       "\n",
       "      degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
       "0     Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
       "1     Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
       "2    Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
       "3     Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
       "4    Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  \n",
       "..         ...    ...      ...            ...    ...         ...       ...  \n",
       "210  Comm&Mgmt     No     91.0        Mkt&Fin  74.49      Placed  400000.0  \n",
       "211   Sci&Tech     No     74.0        Mkt&Fin  53.62      Placed  275000.0  \n",
       "212  Comm&Mgmt    Yes     59.0        Mkt&Fin  69.72      Placed  295000.0  \n",
       "213  Comm&Mgmt     No     70.0         Mkt&HR  60.23      Placed  204000.0  \n",
       "214  Comm&Mgmt     No     89.0         Mkt&HR  60.22  Not Placed       NaN  \n",
       "\n",
       "[215 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "745dce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"ssc_p\", \"hsc_p\", \"degree_p\", \"workex\", \"etest_p\", \"status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16edd6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casa\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "df[\"status\"].replace('Placed', 1, True)\n",
    "df[\"status\"].replace('Not Placed', 0, True)\n",
    "df[\"workex\"].replace('Yes', 1, True)\n",
    "df[\"workex\"].replace('No', 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6e8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.33</td>\n",
       "      <td>78.33</td>\n",
       "      <td>77.48</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.80</td>\n",
       "      <td>73.60</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>80.60</td>\n",
       "      <td>82.00</td>\n",
       "      <td>77.60</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>58.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>67.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>74.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>62.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ssc_p  hsc_p  degree_p  workex  etest_p  status\n",
       "0    67.00  91.00     58.00       0     55.0       1\n",
       "1    79.33  78.33     77.48       1     86.5       1\n",
       "2    65.00  68.00     64.00       0     75.0       1\n",
       "3    56.00  52.00     52.00       0     66.0       0\n",
       "4    85.80  73.60     73.30       0     96.8       1\n",
       "..     ...    ...       ...     ...      ...     ...\n",
       "210  80.60  82.00     77.60       0     91.0       1\n",
       "211  58.00  60.00     72.00       0     74.0       1\n",
       "212  67.00  67.00     73.00       1     59.0       1\n",
       "213  74.00  66.00     58.00       0     70.0       1\n",
       "214  62.00  58.00     53.00       0     89.0       0\n",
       "\n",
       "[215 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa3169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "train_x = train.iloc[:, 0:5]\n",
    "train_y = train.iloc[:, 5]\n",
    "test_x = test.iloc[:, 0:5]\n",
    "test_y = test.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0751e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>75.4</td>\n",
       "      <td>60.50</td>\n",
       "      <td>84.00</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>71.0</td>\n",
       "      <td>58.66</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>85.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>77.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>59.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>63.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>74.00</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>65.0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>0</td>\n",
       "      <td>53.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>69.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>84.2</td>\n",
       "      <td>73.40</td>\n",
       "      <td>66.89</td>\n",
       "      <td>0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>84.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ssc_p  hsc_p  degree_p  workex  etest_p  status\n",
       "152   75.4  60.50     84.00       0     98.0       1\n",
       "150   71.0  58.66     58.00       1     56.0       1\n",
       "90    85.0  90.00     82.00       0     92.0       1\n",
       "117   77.0  75.00     73.00       0     80.0       1\n",
       "105   59.0  64.00     58.00       0     85.0       0\n",
       "..     ...    ...       ...     ...      ...     ...\n",
       "82    63.0  67.00     74.00       0     82.0       0\n",
       "114   65.0  68.00     69.00       0     53.7       1\n",
       "104   69.0  63.00     65.00       1     55.0       1\n",
       "61    84.2  73.40     66.89       0     61.6       1\n",
       "125   84.0  73.00     73.00       0     75.0       1\n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde8b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3a4e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75604396, 0.38714992, 0.97142857, 0.        , 1.        ],\n",
       "       [0.65934066, 0.3568369 , 0.22857143, 1.        , 0.125     ],\n",
       "       [0.96703297, 0.87314662, 0.91428571, 0.        , 0.875     ],\n",
       "       [0.79120879, 0.62602965, 0.65714286, 0.        , 0.625     ],\n",
       "       [0.3956044 , 0.44481054, 0.22857143, 0.        , 0.72916667],\n",
       "       [0.28571429, 0.74135091, 0.37142857, 0.        , 0.        ],\n",
       "       [0.7032967 , 0.67545305, 0.65714286, 1.        , 0.72916667],\n",
       "       [0.43516484, 0.51729819, 0.41714286, 1.        , 0.68041667],\n",
       "       [0.79120879, 0.82372323, 0.25714286, 0.        , 0.375     ],\n",
       "       [0.72527473, 0.59308072, 0.65714286, 1.        , 0.625     ],\n",
       "       [0.37362637, 0.54365733, 0.31428571, 0.        , 0.08333333],\n",
       "       [0.3956044 , 0.41186161, 0.78571429, 0.        , 0.5       ],\n",
       "       [0.52747253, 0.46128501, 0.71428571, 0.        , 0.6875    ],\n",
       "       [0.7032967 , 0.42833608, 0.45714286, 0.        , 0.8125    ],\n",
       "       [0.94505495, 0.88797364, 0.41428571, 0.        , 0.75083333],\n",
       "       [0.46153846, 0.49423394, 0.22857143, 0.        , 0.5625    ],\n",
       "       [0.21978022, 0.2800659 , 0.31428571, 0.        , 0.20833333],\n",
       "       [0.48351648, 0.48105437, 0.44571429, 1.        , 0.20833333],\n",
       "       [0.61538462, 0.59308072, 0.42857143, 0.        , 0.41666667],\n",
       "       [0.50549451, 0.70840198, 0.42857143, 1.        , 0.39583333],\n",
       "       [0.52747253, 0.65897858, 0.54285714, 0.        , 0.20833333],\n",
       "       [0.80879121, 0.44481054, 0.40571429, 0.        , 0.53125   ],\n",
       "       [0.24175824, 0.42833608, 0.42857143, 1.        , 0.75      ],\n",
       "       [0.87032967, 0.74135091, 0.78857143, 0.        , 0.85416667],\n",
       "       [0.51868132, 0.77149918, 0.62057143, 0.        , 0.75      ],\n",
       "       [0.46153846, 0.34596376, 0.08571429, 0.        , 0.8125    ],\n",
       "       [0.24175824, 0.32948929, 0.02285714, 0.        , 0.35416667],\n",
       "       [0.94945055, 0.53377265, 0.42857143, 1.        , 0.625     ],\n",
       "       [0.61538462, 0.41186161, 0.45714286, 0.        , 0.52083333],\n",
       "       [0.7032967 , 0.34596376, 0.45714286, 0.        , 0.07708333],\n",
       "       [0.32087912, 0.2306425 , 0.21428571, 0.        , 0.15895833],\n",
       "       [0.57142857, 0.5107084 , 0.4       , 1.        , 0.50833333],\n",
       "       [0.89450549, 0.42833608, 0.48571429, 1.        , 0.75      ],\n",
       "       [0.72527473, 0.37891269, 0.54285714, 0.        , 0.58333333],\n",
       "       [0.64835165, 0.42009885, 0.31428571, 0.        , 0.91479167],\n",
       "       [0.3956044 , 0.37891269, 0.17142857, 0.        , 0.10416667],\n",
       "       [0.57142857, 0.39538715, 0.62857143, 0.        , 0.45833333],\n",
       "       [0.79120879, 0.39538715, 0.51428571, 1.        , 0.15625   ],\n",
       "       [0.57142857, 0.42833608, 0.4       , 0.        , 0.20833333],\n",
       "       [0.08791209, 0.32948929, 0.22857143, 1.        , 0.133125  ],\n",
       "       [1.        , 0.44810544, 0.49714286, 0.        , 0.1875    ],\n",
       "       [0.48351648, 0.47775947, 0.4       , 0.        , 0.375     ],\n",
       "       [0.37362637, 0.39538715, 0.31428571, 0.        , 0.16666667],\n",
       "       [0.79120879, 0.80724876, 0.17142857, 0.        , 0.14583333],\n",
       "       [0.70857143, 0.22784185, 0.40771429, 1.        , 0.29166667],\n",
       "       [0.57142857, 0.26359143, 0.42857143, 0.        , 0.29166667],\n",
       "       [0.04395604, 0.37891269, 0.42857143, 0.        , 0.88875   ],\n",
       "       [0.9010989 , 0.39538715, 0.34285714, 0.        , 0.8125    ],\n",
       "       [0.7032967 , 0.67545305, 0.42857143, 1.        , 0.94708333],\n",
       "       [0.50549451, 0.54695222, 0.31428571, 0.        , 0.        ],\n",
       "       [0.40879121, 0.2306425 , 0.28571429, 0.        , 0.52083333],\n",
       "       [0.72527473, 0.47775947, 0.22857143, 0.        , 0.41666667],\n",
       "       [0.57142857, 0.49423394, 0.65714286, 1.        , 0.1875    ],\n",
       "       [0.81318681, 0.65897858, 0.85714286, 0.        , 0.20833333],\n",
       "       [0.98461538, 0.6029654 , 0.66571429, 0.        , 0.975     ],\n",
       "       [0.9010989 , 0.44481054, 0.45714286, 1.        , 0.35416667],\n",
       "       [0.48351648, 0.41186161, 0.51428571, 0.        , 0.29166667],\n",
       "       [0.46153846, 0.42833608, 0.4       , 0.        , 0.35416667],\n",
       "       [0.59340659, 0.64250412, 0.68571429, 0.        , 0.625     ],\n",
       "       [0.52747253, 0.5107084 , 0.4       , 0.        , 0.52083333],\n",
       "       [0.        , 0.08237232, 0.28571429, 0.        , 0.97916667],\n",
       "       [0.5978022 , 0.58978583, 0.47428571, 1.        , 0.95833333],\n",
       "       [0.44131868, 0.21416804, 0.11428571, 0.        , 0.4375    ],\n",
       "       [0.94505495, 0.69192751, 0.51428571, 1.        , 0.70833333],\n",
       "       [0.94153846, 0.87034596, 0.77714286, 1.        , 0.59875   ],\n",
       "       [0.52747253, 0.45799012, 0.55714286, 1.        , 0.125     ],\n",
       "       [0.25450549, 0.28995058, 0.00571429, 1.        , 0.54166667],\n",
       "       [0.15384615, 0.2306425 , 0.22857143, 1.        , 0.20833333],\n",
       "       [0.72527473, 0.41186161, 0.51428571, 0.        , 0.5       ],\n",
       "       [0.46153846, 0.41186161, 0.28571429, 1.        , 0.27083333],\n",
       "       [0.74505495, 0.32948929, 0.34285714, 1.        , 0.625     ],\n",
       "       [0.63736264, 0.42833608, 0.45714286, 0.        , 0.235     ],\n",
       "       [0.65934066, 0.69192751, 0.45714286, 1.        , 0.91666667],\n",
       "       [0.57142857, 0.5601318 , 0.40942857, 1.        , 0.29166667],\n",
       "       [0.24175824, 0.24711697, 0.14285714, 0.        , 0.35416667],\n",
       "       [0.7032967 , 0.69192751, 0.62857143, 0.        , 0.86125   ],\n",
       "       [0.13186813, 0.29654036, 0.42857143, 0.        , 0.25      ],\n",
       "       [0.85714286, 0.59308072, 0.71428571, 0.        , 0.22916667],\n",
       "       [0.43956044, 0.54365733, 0.4       , 0.        , 0.38541667],\n",
       "       [0.46153846, 0.16474465, 0.        , 0.        , 0.54166667],\n",
       "       [0.96703297, 0.37891269, 0.66942857, 1.        , 0.20833333],\n",
       "       [0.72967033, 0.83360791, 0.77857143, 1.        , 0.525     ],\n",
       "       [0.61538462, 0.46128501, 0.2       , 0.        , 0.47916667],\n",
       "       [0.25494505, 0.4708402 , 0.63171429, 0.        , 0.15833333],\n",
       "       [0.37362637, 0.37891269, 0.62857143, 0.        , 0.5       ],\n",
       "       [0.1978022 , 0.        , 0.05714286, 0.        , 0.3125    ],\n",
       "       [0.41758242, 0.42833608, 0.17142857, 1.        , 0.625     ],\n",
       "       [0.52747253, 0.62602965, 0.54285714, 1.        , 0.45833333],\n",
       "       [0.46153846, 0.57660626, 0.42857143, 0.        , 0.35416667],\n",
       "       [0.93032967, 0.67545305, 0.31428571, 1.        , 0.80333333],\n",
       "       [0.48351648, 0.49423394, 0.45714286, 0.        , 0.375     ],\n",
       "       [0.53186813, 0.40197694, 0.42285714, 1.        , 0.90416667],\n",
       "       [0.56043956, 0.49093904, 0.55142857, 1.        , 0.63333333],\n",
       "       [0.26373626, 0.42833608, 0.28571429, 1.        , 0.41666667],\n",
       "       [0.61538462, 0.67545305, 0.62857143, 0.        , 0.4375    ],\n",
       "       [0.43956044, 0.72487644, 0.46857143, 0.        , 0.01854167],\n",
       "       [0.23230769, 0.62042834, 0.28285714, 1.        , 0.128125  ],\n",
       "       [0.30769231, 0.49423394, 0.4       , 0.        , 0.20833333],\n",
       "       [0.57142857, 0.42833608, 0.62857143, 0.        , 0.125     ],\n",
       "       [0.83516484, 0.64250412, 0.44571429, 0.        , 0.16666667],\n",
       "       [0.24175824, 0.29654036, 0.18      , 0.        , 0.1875    ],\n",
       "       [0.29450549, 0.39736409, 0.17714286, 0.        , 0.35416667],\n",
       "       [0.7032967 , 0.59308072, 0.45714286, 1.        , 0.41666667],\n",
       "       [0.8       , 0.37891269, 0.42114286, 1.        , 0.875     ],\n",
       "       [0.33582418, 0.42553542, 0.27971429, 0.        , 0.20833333],\n",
       "       [0.46153846, 0.46128501, 0.45714286, 0.        , 0.        ],\n",
       "       [0.76923077, 0.70840198, 0.8       , 1.        , 0.97916667],\n",
       "       [0.24175824, 0.41186161, 0.11428571, 0.        , 0.45833333],\n",
       "       [0.82417582, 0.46952224, 0.48571429, 1.        , 0.9375    ],\n",
       "       [0.54945055, 0.44481054, 0.28571429, 0.        , 0.20833333],\n",
       "       [0.83516484, 0.39538715, 0.72857143, 1.        , 0.41666667],\n",
       "       [0.78461538, 0.86820428, 0.45714286, 1.        , 0.83333333],\n",
       "       [0.9010989 , 0.87314662, 0.94285714, 0.        , 0.625     ],\n",
       "       [0.78593407, 0.65074135, 0.5       , 1.        , 0.48645833],\n",
       "       [0.62857143, 0.51729819, 0.80857143, 1.        , 0.20833333],\n",
       "       [0.61538462, 0.37891269, 0.42857143, 0.        , 0.78229167],\n",
       "       [0.72527473, 0.43097199, 0.42857143, 1.        , 0.3125    ],\n",
       "       [0.83516484, 0.64250412, 1.        , 0.        , 0.9375    ],\n",
       "       [0.46153846, 0.38434926, 0.406     , 0.        , 0.27083333],\n",
       "       [0.24175824, 0.46128501, 0.2       , 1.        , 0.52083333],\n",
       "       [0.28571429, 0.16474465, 0.2       , 0.        , 0.826875  ],\n",
       "       [0.7032967 , 0.34596376, 0.17142857, 0.        , 0.70833333],\n",
       "       [0.24175824, 0.44481054, 0.31428571, 0.        , 0.10416667],\n",
       "       [0.7243956 , 0.69192751, 0.48571429, 0.        , 0.46145833],\n",
       "       [0.94505495, 0.62602965, 0.54285714, 1.        , 0.25      ],\n",
       "       [0.30769231, 0.21087315, 0.49285714, 1.        , 0.10416667],\n",
       "       [0.57494505, 0.58484349, 0.38142857, 0.        , 0.06333333],\n",
       "       [0.46153846, 0.2306425 , 0.05714286, 0.        , 0.38416667],\n",
       "       [0.59340659, 0.31301483, 0.51428571, 0.        , 0.47916667],\n",
       "       [0.17582418, 0.36243822, 0.42857143, 1.        , 0.75      ],\n",
       "       [0.46153846, 0.46128501, 0.28571429, 0.        , 0.70833333],\n",
       "       [0.54945055, 0.41186161, 0.65714286, 0.        , 0.16666667],\n",
       "       [0.78021978, 1.        , 0.82457143, 0.        , 0.9875    ],\n",
       "       [0.63076923, 0.16474465, 0.64857143, 0.        , 0.60416667],\n",
       "       [0.63736264, 0.42833608, 0.57142857, 1.        , 0.10416667],\n",
       "       [0.24175824, 0.19769357, 0.22857143, 0.        , 0.25      ],\n",
       "       [0.61538462, 0.41186161, 0.54285714, 1.        , 0.35416667],\n",
       "       [0.43956044, 0.41186161, 0.42857143, 0.        , 0.25      ],\n",
       "       [0.7032967 , 0.98846787, 0.82857143, 1.        , 0.8125    ],\n",
       "       [0.50549451, 0.60131796, 0.65714286, 0.        , 0.04166667],\n",
       "       [0.48351648, 0.56672158, 0.32571429, 0.        , 0.375     ],\n",
       "       [0.80087912, 0.90609555, 0.62857143, 1.        , 0.91666667],\n",
       "       [0.42263736, 0.52718287, 0.45714286, 0.        , 0.45833333],\n",
       "       [0.86593407, 0.59967051, 0.792     , 1.        , 0.65      ],\n",
       "       [0.32967033, 0.24711697, 0.05714286, 0.        , 0.33333333],\n",
       "       [0.48351648, 0.49423394, 0.68571429, 0.        , 0.66666667],\n",
       "       [0.52747253, 0.5107084 , 0.54285714, 0.        , 0.07708333],\n",
       "       [0.61538462, 0.42833608, 0.42857143, 1.        , 0.10416667],\n",
       "       [0.94945055, 0.59967051, 0.48257143, 0.        , 0.24166667],\n",
       "       [0.94505495, 0.59308072, 0.65714286, 0.        , 0.52083333]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8cf6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.59713814\n",
      "Iteration 2, loss = 0.59584213\n",
      "Iteration 3, loss = 0.59455683\n",
      "Iteration 4, loss = 0.59328128\n",
      "Iteration 5, loss = 0.59201712\n",
      "Iteration 6, loss = 0.59076830\n",
      "Iteration 7, loss = 0.58953449\n",
      "Iteration 8, loss = 0.58831297\n",
      "Iteration 9, loss = 0.58709509\n",
      "Iteration 10, loss = 0.58588789\n",
      "Iteration 11, loss = 0.58468578\n",
      "Iteration 12, loss = 0.58348598\n",
      "Iteration 13, loss = 0.58230262\n",
      "Iteration 14, loss = 0.58112861\n",
      "Iteration 15, loss = 0.57996851\n",
      "Iteration 16, loss = 0.57880841\n",
      "Iteration 17, loss = 0.57766011\n",
      "Iteration 18, loss = 0.57652662\n",
      "Iteration 19, loss = 0.57540580\n",
      "Iteration 20, loss = 0.57429130\n",
      "Iteration 21, loss = 0.57318589\n",
      "Iteration 22, loss = 0.57208542\n",
      "Iteration 23, loss = 0.57099632\n",
      "Iteration 24, loss = 0.56991123\n",
      "Iteration 25, loss = 0.56882712\n",
      "Iteration 26, loss = 0.56774528\n",
      "Iteration 27, loss = 0.56666419\n",
      "Iteration 28, loss = 0.56558431\n",
      "Iteration 29, loss = 0.56450619\n",
      "Iteration 30, loss = 0.56342810\n",
      "Iteration 31, loss = 0.56235177\n",
      "Iteration 32, loss = 0.56127716\n",
      "Iteration 33, loss = 0.56020359\n",
      "Iteration 34, loss = 0.55912899\n",
      "Iteration 35, loss = 0.55805354\n",
      "Iteration 36, loss = 0.55698051\n",
      "Iteration 37, loss = 0.55591286\n",
      "Iteration 38, loss = 0.55484357\n",
      "Iteration 39, loss = 0.55377244\n",
      "Iteration 40, loss = 0.55269836\n",
      "Iteration 41, loss = 0.55162806\n",
      "Iteration 42, loss = 0.55055297\n",
      "Iteration 43, loss = 0.54947497\n",
      "Iteration 44, loss = 0.54839347\n",
      "Iteration 45, loss = 0.54730623\n",
      "Iteration 46, loss = 0.54622319\n",
      "Iteration 47, loss = 0.54514558\n",
      "Iteration 48, loss = 0.54407417\n",
      "Iteration 49, loss = 0.54300385\n",
      "Iteration 50, loss = 0.54193332\n",
      "Iteration 51, loss = 0.54086320\n",
      "Iteration 52, loss = 0.53979428\n",
      "Iteration 53, loss = 0.53872460\n",
      "Iteration 54, loss = 0.53766188\n",
      "Iteration 55, loss = 0.53660714\n",
      "Iteration 56, loss = 0.53555134\n",
      "Iteration 57, loss = 0.53450816\n",
      "Iteration 58, loss = 0.53347116\n",
      "Iteration 59, loss = 0.53243806\n",
      "Iteration 60, loss = 0.53140447\n",
      "Iteration 61, loss = 0.53037330\n",
      "Iteration 62, loss = 0.52934289\n",
      "Iteration 63, loss = 0.52830966\n",
      "Iteration 64, loss = 0.52727916\n",
      "Iteration 65, loss = 0.52625311\n",
      "Iteration 66, loss = 0.52523699\n",
      "Iteration 67, loss = 0.52422804\n",
      "Iteration 68, loss = 0.52321910\n",
      "Iteration 69, loss = 0.52221364\n",
      "Iteration 70, loss = 0.52120953\n",
      "Iteration 71, loss = 0.52020722\n",
      "Iteration 72, loss = 0.51920676\n",
      "Iteration 73, loss = 0.51821170\n",
      "Iteration 74, loss = 0.51721638\n",
      "Iteration 75, loss = 0.51622010\n",
      "Iteration 76, loss = 0.51522911\n",
      "Iteration 77, loss = 0.51423779\n",
      "Iteration 78, loss = 0.51324611\n",
      "Iteration 79, loss = 0.51225473\n",
      "Iteration 80, loss = 0.51126496\n",
      "Iteration 81, loss = 0.51027618\n",
      "Iteration 82, loss = 0.50928813\n",
      "Iteration 83, loss = 0.50829950\n",
      "Iteration 84, loss = 0.50731333\n",
      "Iteration 85, loss = 0.50633219\n",
      "Iteration 86, loss = 0.50535197\n",
      "Iteration 87, loss = 0.50437084\n",
      "Iteration 88, loss = 0.50338757\n",
      "Iteration 89, loss = 0.50240395\n",
      "Iteration 90, loss = 0.50141965\n",
      "Iteration 91, loss = 0.50043405\n",
      "Iteration 92, loss = 0.49944642\n",
      "Iteration 93, loss = 0.49845988\n",
      "Iteration 94, loss = 0.49747191\n",
      "Iteration 95, loss = 0.49648893\n",
      "Iteration 96, loss = 0.49550773\n",
      "Iteration 97, loss = 0.49452521\n",
      "Iteration 98, loss = 0.49354383\n",
      "Iteration 99, loss = 0.49256212\n",
      "Iteration 100, loss = 0.49158143\n",
      "Iteration 101, loss = 0.49060414\n",
      "Iteration 102, loss = 0.48962943\n",
      "Iteration 103, loss = 0.48865446\n",
      "Iteration 104, loss = 0.48768247\n",
      "Iteration 105, loss = 0.48671477\n",
      "Iteration 106, loss = 0.48575644\n",
      "Iteration 107, loss = 0.48480260\n",
      "Iteration 108, loss = 0.48384928\n",
      "Iteration 109, loss = 0.48289776\n",
      "Iteration 110, loss = 0.48194519\n",
      "Iteration 111, loss = 0.48099480\n",
      "Iteration 112, loss = 0.48004615\n",
      "Iteration 113, loss = 0.47909733\n",
      "Iteration 114, loss = 0.47814745\n",
      "Iteration 115, loss = 0.47719783\n",
      "Iteration 116, loss = 0.47625401\n",
      "Iteration 117, loss = 0.47531165\n",
      "Iteration 118, loss = 0.47437306\n",
      "Iteration 119, loss = 0.47343577\n",
      "Iteration 120, loss = 0.47249923\n",
      "Iteration 121, loss = 0.47156384\n",
      "Iteration 122, loss = 0.47063304\n",
      "Iteration 123, loss = 0.46970308\n",
      "Iteration 124, loss = 0.46877325\n",
      "Iteration 125, loss = 0.46784583\n",
      "Iteration 126, loss = 0.46692004\n",
      "Iteration 127, loss = 0.46599767\n",
      "Iteration 128, loss = 0.46508109\n",
      "Iteration 129, loss = 0.46416660\n",
      "Iteration 130, loss = 0.46325429\n",
      "Iteration 131, loss = 0.46234432\n",
      "Iteration 132, loss = 0.46143399\n",
      "Iteration 133, loss = 0.46052300\n",
      "Iteration 134, loss = 0.45961314\n",
      "Iteration 135, loss = 0.45870506\n",
      "Iteration 136, loss = 0.45779850\n",
      "Iteration 137, loss = 0.45689307\n",
      "Iteration 138, loss = 0.45599024\n",
      "Iteration 139, loss = 0.45509479\n",
      "Iteration 140, loss = 0.45420159\n",
      "Iteration 141, loss = 0.45331077\n",
      "Iteration 142, loss = 0.45242226\n",
      "Iteration 143, loss = 0.45153897\n",
      "Iteration 144, loss = 0.45065681\n",
      "Iteration 145, loss = 0.44977710\n",
      "Iteration 146, loss = 0.44889970\n",
      "Iteration 147, loss = 0.44802584\n",
      "Iteration 148, loss = 0.44715621\n",
      "Iteration 149, loss = 0.44629029\n",
      "Iteration 150, loss = 0.44542809\n",
      "Iteration 151, loss = 0.44456948\n",
      "Iteration 152, loss = 0.44371354\n",
      "Iteration 153, loss = 0.44286108\n",
      "Iteration 154, loss = 0.44201129\n",
      "Iteration 155, loss = 0.44116538\n",
      "Iteration 156, loss = 0.44032219\n",
      "Iteration 157, loss = 0.43948248\n",
      "Iteration 158, loss = 0.43864645\n",
      "Iteration 159, loss = 0.43781455\n",
      "Iteration 160, loss = 0.43698917\n",
      "Iteration 161, loss = 0.43616845\n",
      "Iteration 162, loss = 0.43534960\n",
      "Iteration 163, loss = 0.43453331\n",
      "Iteration 164, loss = 0.43371885\n",
      "Iteration 165, loss = 0.43290618\n",
      "Iteration 166, loss = 0.43209619\n",
      "Iteration 167, loss = 0.43128990\n",
      "Iteration 168, loss = 0.43048694\n",
      "Iteration 169, loss = 0.42968754\n",
      "Iteration 170, loss = 0.42889066\n",
      "Iteration 171, loss = 0.42809650\n",
      "Iteration 172, loss = 0.42730539\n",
      "Iteration 173, loss = 0.42651749\n",
      "Iteration 174, loss = 0.42573220\n",
      "Iteration 175, loss = 0.42494915\n",
      "Iteration 176, loss = 0.42416860\n",
      "Iteration 177, loss = 0.42339099\n",
      "Iteration 178, loss = 0.42261548\n",
      "Iteration 179, loss = 0.42184127\n",
      "Iteration 180, loss = 0.42106952\n",
      "Iteration 181, loss = 0.42030032\n",
      "Iteration 182, loss = 0.41953357\n",
      "Iteration 183, loss = 0.41876932\n",
      "Iteration 184, loss = 0.41800629\n",
      "Iteration 185, loss = 0.41724552\n",
      "Iteration 186, loss = 0.41648708\n",
      "Iteration 187, loss = 0.41573125\n",
      "Iteration 188, loss = 0.41497794\n",
      "Iteration 189, loss = 0.41422726\n",
      "Iteration 190, loss = 0.41347907\n",
      "Iteration 191, loss = 0.41273135\n",
      "Iteration 192, loss = 0.41198614\n",
      "Iteration 193, loss = 0.41124465\n",
      "Iteration 194, loss = 0.41050566\n",
      "Iteration 195, loss = 0.40976872\n",
      "Iteration 196, loss = 0.40903369\n",
      "Iteration 197, loss = 0.40830141\n",
      "Iteration 198, loss = 0.40757178\n",
      "Iteration 199, loss = 0.40684627\n",
      "Iteration 200, loss = 0.40612722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casa\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=30, random_state=27, validation_fraction=0.2,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "modelo = MLPClassifier(\n",
    "hidden_layer_sizes=(30),\n",
    "activation='relu',\n",
    "solver='adam',\n",
    "learning_rate='constant',\n",
    "learning_rate_init=0.001,\n",
    "max_iter=200,\n",
    "shuffle=True,\n",
    "random_state=27,\n",
    "verbose=True,\n",
    "validation_fraction=0.2)\n",
    "\n",
    "modelo.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d939d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred_y = modelo.predict(test_x)\n",
    "print (\"Acurácia:\", metrics.accuracy_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d45b8c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
